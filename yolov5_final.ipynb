{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRkFXZXeWsWn"
   },
   "source": [
    "# Детекция на примере `yolov5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачиваем датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 46172,
     "status": "ok",
     "timestamp": 1713881701876,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "3yU2Fwc_ttzG",
    "outputId": "d50fa36d-7e8f-4b0f-f7b7-a8e3bb12b3f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Object-Detection-3 to yolov5pytorch:: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 665644/665644 [00:28<00:00, 23484.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Object-Detection-3 in yolov5pytorch:: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 7882/7882 [00:01<00:00, 5042.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"vVzgCl7OcCV2hguH2FcC\")\n",
    "project = rf.workspace(\"cs474-ug2-vehicle-detection\").project(\"object-detection-um7ee\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in car-detection-fuller-1 to yolov5pytorch:: 100%|████████████████████████████████████████████████████████████████████████████████████| 1267277/1267277 [00:58<00:00, 21691.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to car-detection-fuller-1 in yolov5pytorch:: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 17325/17325 [00:03<00:00, 5363.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"vVzgCl7OcCV2hguH2FcC\")\n",
    "project = rf.workspace(\"object-detection-gstrg\").project(\"car-detection-fuller\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Daniil\n",
      "data.yaml  datasets  hyp.yaml  yolov5  yolov5.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxBtH_izcl6G"
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4b112SSbR8i"
   },
   "source": [
    "Клонируем репозиторий [`ultralytics/yolov5`](https://github.com/ultralytics/yolov5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3010,
     "status": "ok",
     "timestamp": 1713881560958,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "LK1jnJDXWx06",
    "outputId": "76a73e52-7290-47f0-b56b-9f476bf2b085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1713881560958,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "DX5PtcKAb6b-",
    "outputId": "650d65dd-d376-4d63-b04e-224412d8170e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Daniil/yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using dhist requires you to install the `pickleshare` library.\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1713881560958,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "OTcQ7PdOb-fA",
    "outputId": "677e10c0-90a5-4305-9c39-5e147f04f320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CITATION.cff     README.zh-CN.md  detect.py   pyproject.toml    tutorial.ipynb\n",
      "CONTRIBUTING.md  benchmarks.py    export.py   requirements.txt  \u001b[0m\u001b[01;34mutils\u001b[0m/\n",
      "LICENSE          \u001b[01;34mclassify\u001b[0m/        hubconf.py  \u001b[01;34msegment\u001b[0m/          val.py\n",
      "README.md        \u001b[01;34mdata\u001b[0m/            \u001b[01;34mmodels\u001b[0m/     train.py\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 68648,
     "status": "ok",
     "timestamp": 1713881629603,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "ltqho5eNcc01",
    "outputId": "8f92e189-9cb7-418d-ea29-bc57a2c647c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'yolov5/requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsyvQ1XZdQOR"
   },
   "source": [
    "## Пробуем запустить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iY5VEbXfckRS"
   },
   "source": [
    "Сначала попробуем запустить код с их обученной моделью, а потом будем пробовать запускать своё обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Mw-00CMuetzw"
   },
   "outputs": [],
   "source": [
    "# %cat data/coco128.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1713881629605,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "RyWNHK3hf9TC",
    "outputId": "ee2d4b88-7f20-445e-b330-fa103a4d0172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/coco128.yaml\n"
     ]
    }
   ],
   "source": [
    "%ls data/coco128.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 26118,
     "status": "ok",
     "timestamp": 1713881655709,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "WtoZAOrhgBPr",
    "outputId": "71f9ae5e-fefc-4540-835e-9eaddb4b6103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=data/coco128.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-306-gb599ae42 Python-3.10.12 torch-2.2.0a0+81ea7a4 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████████████████████████████████| 14.1M/14.1M [00:00<00:00, 17.4MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "\n",
      "Dataset not found ⚠️, missing paths ['/workspace/Daniil/datasets/coco128/images/train2017']\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
      "100%|██████████████████████████████████████| 6.66M/6.66M [00:00<00:00, 11.8MB/s]\n",
      "Dataset download success ✅ (4.4s), saved to \u001b[1m/workspace/Daniil/datasets\u001b[0m\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 2.44MB/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/Daniil/datasets/coco128/labels/train2017... 126 images,\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /workspace/Daniil/datasets/coco128/labels/train2017.cache\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.689      0.634      0.709      0.476\n",
      "Speed: 0.4ms pre-process, 10.8ms inference, 15.7ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights yolov5s.pt --data data/coco128.yaml --imgsz 640 --device 0  # cuda:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UJ7Xza1hRC_"
   },
   "source": [
    "Датасет coco128 был автоматически скачан, посмотрим на структуру датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G8aJbjGYg0se"
   },
   "outputs": [],
   "source": [
    "# %ls ../datasets/coco128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bH7w0DDQhMck"
   },
   "outputs": [],
   "source": [
    "# %ls ../datasets/coco128/images/train2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AZ3VZvJdhZjZ"
   },
   "outputs": [],
   "source": [
    "# %ls ../datasets/coco128/labels/train2017/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKCbWt1Ai_Wg"
   },
   "source": [
    "Посмотрим на то, что представляют из себя файлы с аннотациями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PGjpngGEhn9i"
   },
   "outputs": [],
   "source": [
    "# %cat  ../datasets/coco128/labels/train2017/000000000009.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knNtBV7Okixu"
   },
   "source": [
    "Формат разметки, который здесь используется, называется `yolo`-форматом:\n",
    "\n",
    "`[cls, x_center / img_w, y_center / img_h, w / img_w, h / img_h]`\n",
    "\n",
    "Есть и другие популярные форматы разметки, например, `coco`-формат. А вот что значат цифры в начале:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Hpx6CROjOq9"
   },
   "source": [
    "```text\n",
    "45: bowl\n",
    "46: banana\n",
    "47: apple\n",
    "48: sandwich\n",
    "49: orange\n",
    "50: broccoli\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KDouye3ujH3S"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "__oqxyQEjYtm"
   },
   "outputs": [],
   "source": [
    "# img = cv2.imread('../datasets/coco128/images/train2017/000000000009.jpg')\n",
    "# cv2_imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "caGidF_OjnVV"
   },
   "outputs": [],
   "source": [
    "# !python detect.py --weights yolov5s.pt --source ../datasets/coco128/images/train2017/000000000009.jpg --name some_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7Dxx9Ew2kK2y"
   },
   "outputs": [],
   "source": [
    "# img = cv2.imread('runs/detect/some_name/000000000009.jpg')\n",
    "# cv2_imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50CdgwqFkgD5"
   },
   "source": [
    "Также можно запустить `detect.py` не только на отдельном изображении, но и на папке с изображениями, на потоке, на изображении из сети и т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3m_Lz43oxvr"
   },
   "source": [
    "## Как запустить своё обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X9PQnjLpFPI"
   },
   "source": [
    "Чтобы запустить своё обучение, надо:\n",
    "\n",
    "- Подготовить датасет в `yolo`-формате, создать свой конфиг с путями до данных вида `data/my_data.yaml`. Примеры того, как организовывать файлы в датасет, можно посмотреть в [`data/coco.yaml`](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml) и [`data/VOC.yaml`](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml)\n",
    "- Создать файлик с конфигом, в котором будут прописаны параметры для тренировки, вида `data/hyps/my_hyps.yaml`. Для начала можно попробовать запустить со стандартным [конфигом](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-low.yaml)\n",
    "- Стартовать с весов `yolov5s`, если будете тренировать yolo small; `yolov5n`, если yolo nano, и т.д.\n",
    "![](https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png)\n",
    "- Лучше передавать в `--name` какое-то адекватное название, которое описывает суть эксперимента, чтобы не перепутать потом их между собой\n",
    "- Графики можно смотреть во время обучения, для этого надо запустить в терминале что-то типа:\n",
    "\n",
    "  ` tensorboard --logdir ./runs/train/`\n",
    "\n",
    "  и перейти по ссылке в браузере\n",
    "\n",
    "Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uQs1pVw3iHyi"
   },
   "outputs": [],
   "source": [
    "# !cd ..\n",
    "# !rm -r yolov5\n",
    "# !move \"Object-Detection-3\" \"yolov5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1713881701877,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "puXdMZDrupqX",
    "outputId": "3c7cd71d-bcc2-4d7d-b42d-4b96940db651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CITATION.cff\t __pycache__\texport.py\t  runs\t\t  val.py\n",
      "CONTRIBUTING.md  benchmarks.py\thubconf.py\t  segment\t  yolov5s.pt\n",
      "LICENSE\t\t classify\tmodels\t\t  train.py\n",
      "README.md\t data\t\tpyproject.toml\t  tutorial.ipynb\n",
      "README.zh-CN.md  detect.py\trequirements.txt  utils\n"
     ]
    }
   ],
   "source": [
    "# %cd yolov5\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём необходимые yaml файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "hyp = {\n",
    "    'lr0': 0.001,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    'box': 0.05,\n",
    "    'cls': 0.5,\n",
    "    'cls_pw': 1.0,\n",
    "    'obj': 1.0,\n",
    "    'obj_pw': 1.0,\n",
    "    'iou_t': 0.4,\n",
    "    'anchor_t': 4.0,\n",
    "    'fl_gamma': 0.0,\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.3,\n",
    "    'hsv_v': 0.2,\n",
    "    'degrees': 20.0,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'flipud': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.0,\n",
    "    'copy_paste': 0.0\n",
    "}\n",
    "\n",
    "    \n",
    "with open(\"hyp.yaml\", \"w\") as f:\n",
    "    yaml.dump(hyp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(/kaggle/working/yolov5/Object-Detection-3/data.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(len(os.listdir('/car-detection-fuller-1/train/images')))\n",
    "print(len(os.listdir('/Object-Detection-3/train/images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'train': ['../Object-Detection-3/train/images', '../car-detection-fuller-1/train/images'],\n",
    "    'val': ['../Object-Detection-3/valid/images'],\n",
    "    'nc': 1,\n",
    "    'names': ['vehicle']\n",
    "}\n",
    "\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key='e9b7faf1d7a0ab67389ae0d497c3cac4b74e93a7')\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfwo7UJdkcVi",
    "outputId": "8e1d98a9-b98d-4ae3-f953-6075ecb57fd6"
   },
   "outputs": [],
   "source": [
    "!python train.py --data /kaggle/working/yolov5/data.yaml --hyp /kaggle/working/yolov5/hyp.yaml \\\n",
    "--weights yolov5s.pt --epochs 200 --batch-size 32 --optimizer SGD \\\n",
    "--name lab2_small  --imgsz 1280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtfrN0rNhnO-"
   },
   "source": [
    "Сохраняем результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIGLfxrdvXSU"
   },
   "source": [
    "Какие ещё ключи есть у `train.py`? Идём в скрипт и находим вот такую часть кода, читаем её:\n",
    "\n",
    "```python\n",
    "def parse_opt(known=False):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--weights', type=str, default=ROOT / 'yolov5s.pt', help='initial weights path')\n",
    "    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')\n",
    "    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')\n",
    "    parser.add_argument('--hyp', type=str, default=ROOT / 'data/hyps/hyp.scratch-low.yaml', help='hyperparameters path')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='total training epochs')\n",
    "    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs, -1 for autobatch')\n",
    "    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='train, val image size (pixels)')\n",
    "    parser.add_argument('--rect', action='store_true', help='rectangular training')\n",
    "    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')\n",
    "    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n",
    "    parser.add_argument('--noval', action='store_true', help='only validate final epoch')\n",
    "    parser.add_argument('--noautoanchor', action='store_true', help='disable AutoAnchor')\n",
    "    parser.add_argument('--noplots', action='store_true', help='save no plot files')\n",
    "    parser.add_argument('--evolve', type=int, nargs='?', const=300, help='evolve hyperparameters for x generations')\n",
    "    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n",
    "    parser.add_argument('--cache', type=str, nargs='?', const='ram', help='image --cache ram/disk')\n",
    "    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')\n",
    "    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')\n",
    "    parser.add_argument('--optimizer', type=str, choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer')\n",
    "    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')\n",
    "    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')\n",
    "    parser.add_argument('--project', default=ROOT / 'runs/train', help='save to project/name')\n",
    "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "    parser.add_argument('--quad', action='store_true', help='quad dataloader')\n",
    "    parser.add_argument('--cos-lr', action='store_true', help='cosine LR scheduler')\n",
    "    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')\n",
    "    parser.add_argument('--patience', type=int, default=100, help='EarlyStopping patience (epochs without improvement)')\n",
    "    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone=10, first3=0 1 2')\n",
    "    parser.add_argument('--save-period', type=int, default=-1, help='Save checkpoint every x epochs (disabled if < 1)')\n",
    "    parser.add_argument('--seed', type=int, default=0, help='Global training seed')\n",
    "    parser.add_argument('--local_rank', type=int, default=-1, help='Automatic DDP Multi-GPU argument, do not modify')\n",
    "\n",
    "    # Logger arguments\n",
    "    parser.add_argument('--entity', default=None, help='Entity')\n",
    "    parser.add_argument('--upload_dataset', nargs='?', const=True, default=False, help='Upload data, \"val\" option')\n",
    "    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval')\n",
    "    parser.add_argument('--artifact_alias', type=str, default='latest', help='Version of dataset artifact to use')\n",
    "\n",
    "    return parser.parse_known_args()[0] if known else parser.parse_args()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRFlkxkhtGcb"
   },
   "source": [
    "(10 эпох - это достаточно мало, да и сама эпоха у вас будет занимать гораздо больше времени, ведь coco128 - это маленький датасет для отладки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i97CUWUqv9G3"
   },
   "source": [
    "Приятная опция: прерванные эксперименты можно возобновлять (если нечаянно нажали ctrl + c или потерялось соединение с сервером). Так выглядит код повторного запуска обучения, если вы прервали его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5avWGN8wNqx"
   },
   "outputs": [],
   "source": [
    "# !python train.py --data data/Objects365.yaml --hyp data/hyps/hyp.scratch-low.yaml --weights yolov5m.pt \\\n",
    "# --epochs 5 --batch-size 32 --optimizer SGD --name example_Objects365 --resume runs/train/example_Objects365/weight/last.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRUoZ9c9t-Rn"
   },
   "source": [
    "Провалидировать модель можно при помощи val.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1713881715828,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "s4tFbmIMvf7X",
    "outputId": "2ac7de13-431c-458d-b839-97e5357e6e81"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "# !rm -r yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/DaniilMako/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45DCA_znuQBj"
   },
   "outputs": [],
   "source": [
    "!python val.py --weights yolov5/train/lab2_small/weights/best.pt \\\n",
    "--data Object-Detection-3/data.yaml --imgsz 1280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights /kaggle/working/yolov5/yolov5/weights/best.pt \\\n",
    "--source /kaggle/working/yolov5/yolov5/mixkit-daytime-city-traffic-aerial-view-56-medium.mp4 \\\n",
    "--name test_27_04  --imgsz 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1713881715828,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "Y1Sf0royQn-s",
    "outputId": "8df858bc-0bb7-41d9-8954-f763416f934a"
   },
   "outputs": [],
   "source": [
    "!zip -r /kaggle/working/runs.zip /kaggle/working/yolov5/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1713881715829,
     "user": {
      "displayName": "Даниил Владимирович Маковецкий",
      "userId": "12330401444605609021"
     },
     "user_tz": -420
    },
    "id": "J4N2_Z2H76sO",
    "outputId": "770e21a0-6d25-4b88-a896-3b7efb319d4f"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
